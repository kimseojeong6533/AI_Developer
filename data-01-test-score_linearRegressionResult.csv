import pandas as pd
import numpy as np
import tensorflow as tf


dataset=pd.read_csv('data-01-test-score.csv', names=['x0','x1','x2','y'])
yArr=dataset['y']
#yArr=yArr[:,np.newaxis]
xArr=dataset.iloc[:,[0,1,2]]

with tf.Graph().as_default():  #그래프 실행
    x=tf.placeholder(tf.float32, shape=[None,3])  # 독립변수   [? x 2]
    y=tf.placeholder(tf.float32, shape=None)      # 종속변수   
    w=tf.Variable([[0,0,0]],dtype=tf.float32, name='weight')  #가중치(구해야되는 값)
    b=tf.Variable(0,dtype=tf.float32, name='bias')           #bias값(구해야 되는 값)
    #loss=tf.Variable(tf.zeros([1.,2.]),name='loss')
    
    y_hat=tf.matmul(w,tf.transpose(x))+b  # y^=ax+b
    loss=tf.reduce_mean(tf.square(y-y_hat)) # (y-y^)*(y-y^)이 최소인 값이 loss에 들어감
    
    optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0005)   #GradientDescent 기법 사용
    train=optimizer.minimize(loss)   #GradientDescent의 최소값인 값이 train에 들어감(접선의 기울기가 0에 가장 가까울 때)  #이때, train의 형태는무엇?
    
    init=tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run(init)   #일상의 습관, 약속같은 문장임.(실행합니다~의 뜻)
        for step in range(10000):   #100번 반복
            sess.run(train, feed_dict={x:xArr,y:yArr})  #x_data,y_data가 씨 
            if (step%10==0):
                print(step,sess.run([w,b]))
            
    #print(step,sess.run([w,b]))